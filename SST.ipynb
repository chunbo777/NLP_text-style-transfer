{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SST.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOH01fN22tz3a6dMzA9jBL/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunbo777/NLP_text-style-transfer/blob/master/SST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEOhVQgQIbRz",
        "outputId": "e955245d-5515-4282-d352-8f3afd834d28"
      },
      "source": [
        "!git clone https://github.com/chunbo777/Stable-Style-Transformer\n",
        "!git clone https://github.com/lijuncen/Sentiment-and-Style-Transfer\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "%cd /content/Stable-Style-Transformer/generation_model/yelp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Stable-Style-Transformer'...\n",
            "remote: Enumerating objects: 265, done.\u001b[K\n",
            "remote: Counting objects: 100% (265/265), done.\u001b[K\n",
            "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
            "remote: Total 265 (delta 139), reused 249 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (265/265), 1.54 MiB | 4.80 MiB/s, done.\n",
            "Resolving deltas: 100% (139/139), done.\n",
            "Cloning into 'Sentiment-and-Style-Transfer'...\n",
            "remote: Enumerating objects: 392, done.\u001b[K\n",
            "remote: Total 392 (delta 0), reused 0 (delta 0), pack-reused 392\u001b[K\n",
            "Receiving objects: 100% (392/392), 61.34 MiB | 25.41 MiB/s, done.\n",
            "Resolving deltas: 100% (149/149), done.\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 7.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 71.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 84.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 64.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 7.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "/content/Stable-Style-Transformer/generation_model/yelp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoCa-XnHL3-A",
        "outputId": "3ef72ba5-ee4c-495c-db28-125d3bc34d7a"
      },
      "source": [
        "pip install tensorboardX"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 38.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 92 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 122 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mor6rNIWIjZh",
        "outputId": "59d6bf93-accd-4348-c5ac-4d65d2125d0c"
      },
      "source": [
        "#generation model의 train.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "\n",
        "from transformers import *\n",
        "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "\n",
        "## 초기화\n",
        "from dis_model import *\n",
        "dismodel = findattribute().cuda()\n",
        "dismodel.train()\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "summary = SummaryWriter(logdir='./logs')\n",
        "\n",
        "def main():    \n",
        "    f = open('/content/Stable-Style-Transformer/generation_model/yelp/gpt_yelp_vocab.json')\n",
        "    token2num = json.load(f)\n",
        "\n",
        "    num2token = {}\n",
        "    for key, value in token2num.items():\n",
        "        num2token[value] = key\n",
        "    f.close()\n",
        "\n",
        "    data_path = \"/content/Sentiment-and-Style-Transfer/data\" # customize data path\n",
        "    yelp_neg_path = data_path + \"/yelp/sentiment.train.0\"\n",
        "    yelp_neg_open = open(yelp_neg_path, \"r\")\n",
        "    yelp_neg_dataset = yelp_neg_open.readlines()\n",
        "    neg_len = len(yelp_neg_dataset)\n",
        "    yelp_neg_open.close()\n",
        "\n",
        "    yelp_pos_path = data_path + \"/yelp/sentiment.train.1\"\n",
        "    yelp_pos_open = open(yelp_pos_path, \"r\")\n",
        "    yelp_pos_dataset = yelp_pos_open.readlines()\n",
        "    pos_len = len(yelp_pos_dataset)\n",
        "    yelp_pos_open.close()\n",
        "\n",
        "    \"\"\"training parameter\"\"\"\n",
        "    cls_initial_lr = 0.001\n",
        "    cls_trainer = optim.Adamax(dismodel.cls_params, lr=cls_initial_lr) # initial 0.001\n",
        "    max_grad_norm = 25\n",
        "    batch = 1\n",
        "    epoch = 5\n",
        "    stop_point = pos_len*epoch\n",
        "    \n",
        "    pre_epoch = 0\n",
        "    for start in tqdm(range(0, stop_point)):\n",
        "        ## learing rate decay\n",
        "        now_epoch = (start+1)//pos_len\n",
        "        if now_epoch == 4:\n",
        "            cls_initial_lr = cls_initial_lr/2            \n",
        "            cls_trainer = optim.Adamax(dismodel.cls_params, lr=cls_initial_lr) # initial 0.001\n",
        "            \n",
        "        \"\"\"data start point\"\"\"\n",
        "        neg_start = start%neg_len\n",
        "        pos_start = start%pos_len\n",
        "\n",
        "        \"\"\"data setting\"\"\"\n",
        "        neg_sentence = yelp_neg_dataset[neg_start].strip()\n",
        "        pos_sentence = yelp_pos_dataset[pos_start].strip()                \n",
        "\n",
        "        neg_labels = [] # negative labels\n",
        "        neg_labels.append([1,0])\n",
        "        neg_attribute = torch.from_numpy(np.asarray(neg_labels)).type(torch.FloatTensor).cuda()\n",
        "\n",
        "        pos_labels = [] # positive labels\n",
        "        pos_labels.append([0,1])\n",
        "        pos_attribute = torch.from_numpy(np.asarray(pos_labels)).type(torch.FloatTensor).cuda()\n",
        "\n",
        "        sentences = [neg_sentence, pos_sentence]\n",
        "        attributes = [neg_attribute, pos_attribute]\n",
        "\n",
        "        \"\"\"data input\"\"\"\n",
        "        for i in range(2):\n",
        "            # k=0: negative, k=1: positive\n",
        "            sentence = sentences[i]\n",
        "            attribute = attributes[i] # for generate\n",
        "\n",
        "            token_idx = torch.tensor(gpt_tokenizer.encode(sentence)).unsqueeze(0).cuda()\n",
        "            \n",
        "            dis_out = dismodel.discriminator(token_idx)\n",
        "\n",
        "            \"\"\"calculation loss & traning\"\"\"\n",
        "            # training using discriminator loss\n",
        "            cls_loss = dismodel.cls_loss(attribute, dis_out)\n",
        "            summary.add_scalar('discriminator loss', cls_loss.item(), start)\n",
        "\n",
        "            cls_trainer.zero_grad()\n",
        "            cls_loss.backward() # retain_graph=True\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(dismodel.cls_params, max_grad_norm)            \n",
        "            cls_trainer.step()\n",
        "        \n",
        "        \"\"\"savining point\"\"\"\n",
        "        if (start+1)%pos_len == 0:\n",
        "            random.shuffle(yelp_neg_dataset)\n",
        "            random.shuffle(yelp_pos_dataset)\n",
        "            save_model((start+1)//pos_len)        \n",
        "    save_model('final') # final_model    \n",
        "\n",
        "    \n",
        "def save_model(iter):\n",
        "    if not os.path.exists('models/'):\n",
        "        os.makedirs('models/')\n",
        "    torch.save(dismodel.state_dict(), 'models/cls_model_{}'.format(iter))  \n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    torch.cuda.empty_cache()\n",
        "    main()\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1330205 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "  0%|          | 6115/1330205 [01:48<6:30:57, 56.45it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB11wyBMJukq"
      },
      "source": [
        "#yelp.classifier의 dis_model\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, \"/DATA/joosung/fairseq_master\")\n",
        "\n",
        "class findattribute(nn.Module):\n",
        "    def __init__(self, drop_rate=0, gpu = True):\n",
        "        super(findattribute, self).__init__()\n",
        "        self.gpu = gpu\n",
        "        \n",
        "        self.n_vocab = 50259\n",
        "        self.emb_dim = 256\n",
        "        \n",
        "        \"\"\"idx & length\"\"\"\n",
        "        self.START_IDX = 50257\n",
        "        self.PAD_IDX = 50258\n",
        "        self.EOS_IDX = 50256\n",
        "        \n",
        "        \"\"\"Discriminator(classifier)\"\"\"\n",
        "        self.word_dim = 256\n",
        "        self.word_emb = nn.Embedding(self.n_vocab, self.word_dim, self.PAD_IDX) # 50265x1024\n",
        "        \n",
        "        self.channel_out = 100\n",
        "        self.conv2d_2 = nn.Conv2d(1,self.channel_out,(2,self.word_dim))\n",
        "        self.conv2d_3 = nn.Conv2d(1,self.channel_out,(3,self.word_dim))\n",
        "        self.conv2d_4 = nn.Conv2d(1,self.channel_out,(4,self.word_dim))\n",
        "        self.conv2d_5 = nn.Conv2d(1,self.channel_out,(5,self.word_dim))\n",
        "#         self.fc_drop = nn.Dropout(drop_rate)\n",
        "        self.disc_fc = nn.Linear(4*self.channel_out, 2)\n",
        "        \n",
        "        \"\"\"parameters\"\"\"                \n",
        "        self.cls_params = list(self.word_emb.parameters())+list(self.conv2d_2.parameters())+list(self.conv2d_3.parameters())+list(self.conv2d_4.parameters())+\\\n",
        "        list(self.conv2d_5.parameters())+list(self.disc_fc.parameters())\n",
        "            \n",
        "\n",
        "    def discriminator(self, token_idx):\n",
        "        \"\"\"\n",
        "        token_idx: (batch, seq_len)\n",
        "        \"\"\"\n",
        "        if token_idx.shape[1] < 5:\n",
        "            padding_size = 5-token_idx.shape[1]\n",
        "            padding_token = []\n",
        "            for k in range(token_idx.shape[0]):\n",
        "                temp = []\n",
        "                for i in range(padding_size):\n",
        "                    temp.append(self.PAD_IDX)\n",
        "                padding_token.append(temp)                \n",
        "            padding_token=torch.from_numpy(np.array(padding_token))\n",
        "            if self.gpu == True:\n",
        "                padding_token = padding_token.cuda()\n",
        "            token_idx=torch.cat([token_idx,padding_token], 1) # (batch, seq_len+padding) = (batch, 5)\n",
        "\n",
        "        word_emb = self.word_emb(token_idx) # (batch, seq_len, word_dim)\n",
        "        word_2d = word_emb.unsqueeze(1) # (batch, 1, seq_len, word_dim)\n",
        "\n",
        "        x2 = F.relu(self.conv2d_2(word_2d)).squeeze(3) # bi-gram, (batch, channel_out, seq_len-1)\n",
        "        x3 = F.relu(self.conv2d_3(word_2d)).squeeze(3) # 3-gram, (batch, channel_out, seq_len-2)\n",
        "        x4 = F.relu(self.conv2d_4(word_2d)).squeeze(3) # 4-gram, (batch, channel_out, seq_len-3)\n",
        "        x5 = F.relu(self.conv2d_5(word_2d)).squeeze(3) # 5-gram, (batch, channel_out, seq_len-4)\n",
        "\n",
        "        # Max-over-time-pool\n",
        "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x4 = F.max_pool1d(x4, x4.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x5 = F.max_pool1d(x5, x5.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x = torch.cat([x2, x3, x4, x5], dim=1) # (batch, channel_out*4)\n",
        "\n",
        "        y = self.disc_fc(x) # (batch, 2)\n",
        "\n",
        "        if self.gpu == True:\n",
        "            return y.cuda()\n",
        "        else:\n",
        "            return y\n",
        "        \n",
        "    def gen_discriminator(self, gen_out):\n",
        "        \"\"\"\n",
        "        gen_out: (gen_len+2, batch, n_vocab)\n",
        "        \"\"\"\n",
        "        gen_emb = gen_out[1:-1,:,:] # (gen_len, batch, n_vocab)\n",
        "        gen_emb = torch.bmm(gen_emb, self.word_emb.weight.repeat(gen_emb.shape[0],1,1))\n",
        "        # (gen_len, batch, emb_dim) = (gen_len, batch, n_vocab) x (gen_len, n_vocab, emb_dim)\n",
        "        gen_emb = gen_emb.transpose(0, 1) # (batch, gen_len, word_dim)\n",
        "        \n",
        "        if gen_emb.shape[1] < 5:\n",
        "            padding_size = 5-gen_emb.shape[1]\n",
        "            padding_token = []\n",
        "            for k in range(gen_emb.shape[0]):\n",
        "                temp = []\n",
        "                for i in range(padding_size):\n",
        "                    temp.append(self.PAD_IDX)\n",
        "                padding_token.append(temp)                \n",
        "            padding_token=torch.from_numpy(np.array(padding_token)) # (batch, padding_len)\n",
        "            if self.gpu == True:\n",
        "                padding_token = padding_token.cuda()\n",
        "            padding_emb = self.word_emb(padding_token) # (batch, padding_len, emb_dim)\n",
        "            gen_emb = torch.cat([gen_emb, padding_emb], 1) # (batch, 5, emb_dim)   \n",
        "            \n",
        "        word_2d = gen_emb.unsqueeze(1) # (batch, 1, seq_len, word_dim)\n",
        "\n",
        "        x2 = F.relu(self.conv2d_2(word_2d)).squeeze(3) # bi-gram, (batch, channel_out, seq_len-1)\n",
        "        x3 = F.relu(self.conv2d_3(word_2d)).squeeze(3) # 3-gram, (batch, channel_out, seq_len-2)\n",
        "        x4 = F.relu(self.conv2d_4(word_2d)).squeeze(3) # 4-gram, (batch, channel_out, seq_len-3)\n",
        "        x5 = F.relu(self.conv2d_5(word_2d)).squeeze(3) # 5-gram, (batch, channel_out, seq_len-4)\n",
        "\n",
        "        # Max-over-time-pool\n",
        "        x2 = F.max_pool1d(x2, x2.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x3 = F.max_pool1d(x3, x3.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x4 = F.max_pool1d(x4, x4.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x5 = F.max_pool1d(x5, x5.size(2)).squeeze(2) # (batch, channel_out)\n",
        "        x = torch.cat([x2, x3, x4, x5], dim=1) # (batch, channel_out*4)\n",
        "\n",
        "        y = self.disc_fc(x) # (batch, 2)\n",
        "\n",
        "        if self.gpu == True:\n",
        "            return y.cuda()\n",
        "        else:\n",
        "            return y\n",
        "        \n",
        "    def att_prob(self, token_idx, sentiment):\n",
        "        \"\"\"\n",
        "        token_idx: (batch, seq_len)\n",
        "        \"\"\"\n",
        "#         if token_idx.size(1) < 5:\n",
        "#             padding_size = 5-token_idx.size(1)\n",
        "#             padding_token = []\n",
        "#             for k in range(token_idx.size(0)):\n",
        "#                 temp = []\n",
        "#                 for i in range(padding_size):\n",
        "#                     temp.append(self.PAD_IDX)\n",
        "#                 padding_token.append(temp)                \n",
        "#             padding_token=torch.from_numpy(np.array(padding_token))\n",
        "#             if self.gpu == True:\n",
        "#                 padding_token = padding_token.cuda()\n",
        "#             token_idx=torch.cat([token_idx,padding_token], 1) # (batch, seq_len+padding) = (batch, 5)\n",
        "        token_list = token_idx.squeeze(0).cpu().tolist() # list\n",
        "        min_prob = 1\n",
        "        for i in range(len(token_list)):\n",
        "            del_list = token_list[:i] + token_list[i+1:]\n",
        "            del_tensor = torch.from_numpy(np.asarray(del_list)).unsqueeze(0).cuda()\n",
        "            del_prob=F.softmax(self.discriminator(del_tensor),1).squeeze(0)[sentiment].cpu().detach().numpy().item()\n",
        "            \n",
        "            if del_prob <= min_prob:                \n",
        "                max_ind = i\n",
        "                min_prob = del_prob\n",
        "                \n",
        "        final_list = token_list[:max_ind] + token_list[max_ind+1:]\n",
        "        del_idx = torch.from_numpy(np.asarray(final_list)).unsqueeze(0).cuda()\n",
        "        return del_idx    \n",
        "        \n",
        "    def cls_loss(self, targets, cls_out):\n",
        "        \"\"\"\n",
        "        targets: (batch, 2) / attributes [0,1] or [1,0]\n",
        "        cls_out: (batch, 2) (logits)\n",
        "        \"\"\"\n",
        "        \n",
        "        final_targets = targets.argmax(1) # (batch)\n",
        "        cls_loss = F.cross_entropy(cls_out, final_targets)\n",
        "        \n",
        "        if self.gpu == True:       \n",
        "            return cls_loss.cuda()\n",
        "        else:\n",
        "            return cls_loss\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}